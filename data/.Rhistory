x= "Time [days]",
y= "Cases") +
scale_color_manual(labels = c("Data","Model"), values = c("red", "blue"))
max(SQ.data$C)
estimParms['N']
## Quick look at the daily incidence of CEN Outbreak 5
ggplot(CEN.data, aes(time, C)) +
geom_col() +
labs(title = "Daily Incidence of CEN Outbreak 5",
y = "Cumulative incidence")
## Extract one outbreak: Centinela State Prison (CEN) Outbreak 5
CEN.data <- all.data %>%
filter(Facility_Outbreak == "Centinela State Prison (CEN) Outbreak 5") %>%
select(Date, Daily_New_Cases) %>%
slice(-1) %>%  # remove first date with 0 new cases
rename(incidence = Daily_New_Cases) %>%
mutate(C = cumsum(incidence)) %>%  # calculate cumulative incidence
mutate(time = seq(0,nrow(.)-1))
CEN.data
## Quick look at the daily incidence of CEN Outbreak 5
ggplot(CEN.data, aes(time, incidence)) +
geom_col() +
labs(title = "Daily Incidence of CEN Outbreak 5",
y = "Cumulative incidence")
## Quick look at the cumulative incidence of CEN Outbreak 5
ggplot(CEN.data, aes(time, C)) +
geom_col() +
labs(title = "Cumulative Incidence of CEN Outbreak 5",
y = "Cumulative incidence")
## Define time sequence and initial conditions
time.out2 <- seq(0, max(CEN.data$time), 1)
init.prison <- init_cond(initI = CEN.data$C[1])
## Use optim to estimate R0
prison.estim <- optim(par = c(log_R0 = log(1), log_N = log(1000))
, objFXN
, fixed.params = disease_params()  # defined at top of script
, obsDat = CEN.data
, init = init.prison
, tseq = time.out2
, control = list(trace = 3, maxit = 150)
, method = "SANN")
## Feed the last parameters of SANN in as the first values of Nelder-Mead
prison.estim <- optim(par = prison.estim$par
, objFXN
, fixed.params = disease_params()
, obsDat = CEN.data
, init = init.prison
, tseq = time.out2
, control = list(trace = 3, maxit = 800, reltol = 10^-7)
, method = "Nelder-Mead"
, hessian = T)
## Store estimates
MLEfits <- prison.estim$par
log_R0.fit <- MLEfits["log_R0"]
log_N.fit <- MLEfits["log_N"]
estimParms <- exp(unname(MLEfits))
names(estimParms) <- c('R0', 'N')
## View the R0 and N estimates
estimParms
## Run the SEIR model with the R0 and N estimates
prison.ts <- simEpidemic(init.prison, time.out2, seixc, disease_params(R0 = estimParms['R0'], N = estimParms['N']))
df2 <- rbind(SQ.data %>%
select(C, time) %>%
mutate(variable = "SQ.data"),
prison.ts %>%
select(C, time) %>%
mutate(variable = "prison.ts"))
df2 <- rbind(CEN.data %>%
select(C, time) %>%
mutate(variable = "CEN.data"),
prison.ts %>%
select(C, time) %>%
mutate(variable = "prison.ts"))
ggplot(df2, aes(x = time, y = C, color = variable))+
geom_line() +
geom_point(data = subset(df2, df2$variable == "CEN.data"), mapping=aes(x = time, y=C, color = variable)) +
labs(title = "Comparing incidence of data and model",
subtitle = paste("CEN Outbreak 5 data
Estimates: R0 = ", round(estimParms['R0'],2), ", N = ", round(estimParms['N'],2)),
x= "Time [days]",
y= "Cases") +
scale_color_manual(labels = c("Data","Model"), values = c("red", "blue"))
max(SQ.data$C)
estimParms['N']
## Generate contour plots with the Hessian ##
fisherInfMatrix <- solve(prison.estim$hessian)
## Create a sequence of R0 and N values for the grid
res <- 15
R0.seq <- exp(seq(log_R0.fit-1, log_R0.fit+1, l = res))
N.seq <- exp(seq(log_N.fit-1, log_N.fit + 1, l = res))
## Initialize plot of parameters
plot(1,1, type = 'n', log = 'xy',
# xlim = range(R0.seq), ylim = range(N.seq),
xlim = c(2.90,2.95), ylim = c(842,843),  # use these limits to zoom-in
las = 1,
xlab = expression(R0), ylab = expression(N),
main = "-log(likelihood) contours", bty = "n")
## Add MLE to the plot
points(estimParms['R0'], estimParms['N'], pch = 16, cex = 2, col = 'black')
## Initialize plot of parameters
plot(1,1, type = 'n', log = 'xy',
# xlim = range(R0.seq), ylim = range(N.seq),
xlim = c(2.93,2.95), ylim = c(842,843),  # use these limits to zoom-in
las = 1,
xlab = expression(R0), ylab = expression(N),
main = "-log(likelihood) contours", bty = "n")
## Add MLE to the plot
points(estimParms['R0'], estimParms['N'], pch = 16, cex = 2, col = 'black')
## Add 95% contour ellipse from Hessian
lines(exp(ellipse(fisherInfMatrix, centre = MLEfits, level = .95)))
legend("topleft", c('MLE', '95% Confidence Region'), lty = c(NA, 1), pch = c(16, NA),
col = c('black', 'black'), bg='white', bty = 'n')
## Initialize plot of parameters
plot(1,1, type = 'n', log = 'xy',
# xlim = range(R0.seq), ylim = range(N.seq),
xlim = c(2.93,2.95), ylim = c(841,843),  # use these limits to zoom-in
las = 1,
xlab = expression(R0), ylab = expression(N),
main = "-log(likelihood) contours", bty = "n")
## Add MLE to the plot
points(estimParms['R0'], estimParms['N'], pch = 16, cex = 2, col = 'black')
## Add 95% contour ellipse from Hessian
lines(exp(ellipse(fisherInfMatrix, centre = MLEfits, level = .95)))
legend("topleft", c('MLE', '95% Confidence Region'), lty = c(NA, 1), pch = c(16, NA),
col = c('black', 'black'), bg='white', bty = 'n')
## Generate contour plots with likelihood profiles ##
mat <- outer(R0.seq, N.seq, objXR0_NVEC, init = init.prison, tseq=time.out2, obsDat=SQ.data)
ml.val <- prison.estim$value
conf.cutoff <- ml.val + qchisq(.95,2)/2
## Show likelihood contours
par(cex = 1.2)
plot(1,1, type = 'n', log = 'xy',
# xlim = range(R0.seq), ylim = range(N.seq),
xlim = c(6.21,6.24), ylim = c(1670,1690),  # use these limits to zoom into the Fisher information matrix contour
# xlim = c(6.227,6.228), ylim = c(1681,1683),   # use these limits to zoom into the profile likelihood contour
xlab = expression(R0), ylab = expression(N),
main = "-log(likelihood) contours", bty = "n")
plot(1,1, type = 'n', log = 'xy',
# xlim = range(R0.seq), ylim = range(N.seq),
xlim = c(2.93,2.95), ylim = c(841,843),  # use these limits to zoom into the Fisher information matrix contour
# xlim = c(6.227,6.228), ylim = c(1681,1683),   # use these limits to zoom into the profile likelihood contour
xlab = expression(R0), ylab = expression(N),
main = "-log(likelihood) contours", bty = "n")
.filled.contour(R0.seq, N.seq, mat, levels = seq(min(mat), max(mat), l=20), col = topo.colors(20))
## Add contour for 95% CI from likelihood ratio
## This comes out extremely small
## Change xlim and ylim to zoom-in further
contour(R0.seq, N.seq, mat, levels = c(conf.cutoff),
col = "black", lwd = 2, labels = "", labcex = .2, add = T)
## Add contour for 95% CI from Hessian
lines(exp(ellipse(fisherInfMatrix, centre = MLEfits, level = .95)), lty = 2)
## Add MLE to the plot
points(exp(log_R0.fit), exp(log_N.fit), pch = 16, cex = 1, col = 'black')
## Add true parameter values to the plot
legend("topleft",
c('MLE', '95% contour (profile likelihood)', '95% contour (Fisher information matrix)')
, lty = c(NA, 1, 2), pch = c(16, NA, NA),
col = c(rep('black',3)), bg='white', bty = 'n')
par(cex = 1.2)
plot(1,1, type = 'n', log = 'xy',
# xlim = range(R0.seq), ylim = range(N.seq),
xlim = c(2.943,2.945), ylim = c(842,842.5),  # use these limits to zoom into the Fisher information matrix contour
# xlim = c(6.227,6.228), ylim = c(1681,1683),   # use these limits to zoom into the profile likelihood contour
xlab = expression(R0), ylab = expression(N),
main = "-log(likelihood) contours", bty = "n")
.filled.contour(R0.seq, N.seq, mat, levels = seq(min(mat), max(mat), l=20), col = topo.colors(20))
## Add contour for 95% CI from likelihood ratio
## This comes out extremely small
## Change xlim and ylim to zoom-in further
contour(R0.seq, N.seq, mat, levels = c(conf.cutoff),
col = "black", lwd = 2, labels = "", labcex = .2, add = T)
## Add contour for 95% CI from Hessian
lines(exp(ellipse(fisherInfMatrix, centre = MLEfits, level = .95)), lty = 2)
## Add MLE to the plot
points(exp(log_R0.fit), exp(log_N.fit), pch = 16, cex =
)
max(CEN.data$C)   # end size of the outbreak
estimParms['N']  # the estimated N
par(cex = 1.2)
plot(1,1, type = 'n', log = 'xy',
# xlim = range(R0.seq), ylim = range(N.seq),
xlim = c(2.941,2.943), ylim = c(842,842.5),  # use these limits to zoom into the Fisher information matrix contour
# xlim = c(6.227,6.228), ylim = c(1681,1683),   # use these limits to zoom into the profile likelihood contour
xlab = expression(R0), ylab = expression(N),
main = "-log(likelihood) contours", bty = "n")
.filled.contour(R0.seq, N.seq, mat, levels = seq(min(mat), max(mat), l=20), col = topo.colors(20))
## Add contour for 95% CI from likelihood ratio
## This comes out extremely small
## Change xlim and ylim to zoom-in further
contour(R0.seq, N.seq, mat, levels = c(conf.cutoff),
col = "black", lwd = 2, labels = "", labcex = .2, add = T)
## Add contour for 95% CI from Hessian
lines(exp(ellipse(fisherInfMatrix, centre = MLEfits, level = .95)), lty = 2)
## Add MLE to the plot
points(exp(log_R0.fit), exp(log_N.fit), pch = 16, cex = 1, col = 'black')
## Add true parameter values to the plot
legend("topleft",
c('MLE', '95% contour (profile likelihood)', '95% contour (Fisher information matrix)')
, lty = c(NA, 1, 2), pch = c(16, NA, NA),
col = c(rep('black',3)), bg='white', bty = 'n')
par(cex = 1.2)
plot(1,1, type = 'n', log = 'xy',
# xlim = range(R0.seq), ylim = range(N.seq),
xlim = c(2.9425,2.9430), ylim = c(842,842.5),  # use these limits to zoom into the Fisher information matrix contour
# xlim = c(6.227,6.228), ylim = c(1681,1683),   # use these limits to zoom into the profile likelihood contour
xlab = expression(R0), ylab = expression(N),
main = "-log(likelihood) contours", bty = "n")
.filled.contour(R0.seq, N.seq, mat, levels = seq(min(mat), max(mat), l=20), col = topo.colors(20))
## Add contour for 95% CI from likelihood ratio
## This comes out extremely small
## Change xlim and ylim to zoom-in further
contour(R0.seq, N.seq, mat, levels = c(conf.cutoff),
col = "black", lwd = 2, labels = "", labcex = .2, add = T)
## Add contour for 95% CI from Hessian
lines(exp(ellipse(fisherInfMatrix, centre = MLEfits, level = .95)), lty = 2)
## Add MLE to the plot
points(exp(log_R0.fit), exp(log_N.fit), pch = 16, cex = 1, col = 'black')
## Add true parameter values to the plot
legend("topleft",
c('MLE', '95% contour (profile likelihood)', '95% contour (Fisher information matrix)')
, lty = c(NA, 1, 2), pch = c(16, NA, NA),
col = c(rep('black',3)), bg='white', bty = 'n')
conf.cutoff
par(cex = 1.2)
plot(1,1, type = 'n', log = 'xy',
# xlim = range(R0.seq), ylim = range(N.seq),
xlim = c(2.9428,2.9429), ylim = c(842.1,842.2),  # use these limits to zoom into the Fisher information matrix contour
# xlim = c(6.227,6.228), ylim = c(1681,1683),   # use these limits to zoom into the profile likelihood contour
xlab = expression(R0), ylab = expression(N),
main = "-log(likelihood) contours", bty = "n")
.filled.contour(R0.seq, N.seq, mat, levels = seq(min(mat), max(mat), l=20), col = topo.colors(20))
## Add contour for 95% CI from likelihood ratio
## This comes out extremely small
## Change xlim and ylim to zoom-in further
contour(R0.seq, N.seq, mat, levels = c(conf.cutoff),
col = "black", lwd = 2, labels = "", labcex = .2, add = T)
## Add contour for 95% CI from Hessian
lines(exp(ellipse(fisherInfMatrix, centre = MLEfits, level = .95)), lty = 2)
## Add MLE to the plot
points(exp(log_R0.fit), exp(log_N.fit), pch = 16, cex = 1, col = 'black')
## Add true parameter values to the plot
legend("topleft",
c('MLE', '95% contour (profile likelihood)', '95% contour (Fisher information matrix)')
, lty = c(NA, 1, 2), pch = c(16, NA, NA),
col = c(rep('black',3)), bg='white', bty = 'n')
par(cex = 1.2)
plot(1,1, type = 'n', log = 'xy',
# xlim = range(R0.seq), ylim = range(N.seq),
xlim = c(2.9428,2.9429), ylim = c(842.14,842.18),  # use these limits to zoom into the Fisher information matrix contour
# xlim = c(6.227,6.228), ylim = c(1681,1683),   # use these limits to zoom into the profile likelihood contour
xlab = expression(R0), ylab = expression(N),
main = "-log(likelihood) contours", bty = "n")
.filled.contour(R0.seq, N.seq, mat, levels = seq(min(mat), max(mat), l=20), col = topo.colors(20))
## Add contour for 95% CI from likelihood ratio
## This comes out extremely small
## Change xlim and ylim to zoom-in further
contour(R0.seq, N.seq, mat, levels = c(conf.cutoff),
col = "black", lwd = 2, labels = "", labcex = .2, add = T)
## Add contour for 95% CI from Hessian
lines(exp(ellipse(fisherInfMatrix, centre = MLEfits, level = .95)), lty = 2)
## Add MLE to the plot
points(exp(log_R0.fit), exp(log_N.fit), pch = 16, cex = 1, col = 'black')
## Add true parameter values to the plot
legend("topleft",
c('MLE', '95% contour (profile likelihood)', '95% contour (Fisher information matrix)')
, lty = c(NA, 1, 2), pch = c(16, NA, NA),
col = c(rep('black',3)), bg='white', bty = 'n')
par(cex = 1.2)
plot(1,1, type = 'n', log = 'xy',
# xlim = range(R0.seq), ylim = range(N.seq),
xlim = c(2.94280,2.94284), ylim = c(842.16,842.17),  # use these limits to zoom into the Fisher information matrix contour
# xlim = c(6.227,6.228), ylim = c(1681,1683),   # use these limits to zoom into the profile likelihood contour
xlab = expression(R0), ylab = expression(N),
main = "-log(likelihood) contours", bty = "n")
.filled.contour(R0.seq, N.seq, mat, levels = seq(min(mat), max(mat), l=20), col = topo.colors(20))
## Add contour for 95% CI from likelihood ratio
## This comes out extremely small
## Change xlim and ylim to zoom-in further
contour(R0.seq, N.seq, mat, levels = c(conf.cutoff),
col = "black", lwd = 2, labels = "", labcex = .2, add = T)
## Add contour for 95% CI from Hessian
lines(exp(ellipse(fisherInfMatrix, centre = MLEfits, level = .95)), lty = 2)
## Add MLE to the plot
points(exp(log_R0.fit), exp(log_N.fit), pch = 16, cex = 1, col = 'black')
## Add true parameter values to the plot
legend("topleft",
c('MLE', '95% contour (profile likelihood)', '95% contour (Fisher information matrix)')
, lty = c(NA, 1, 2), pch = c(16, NA, NA),
col = c(rep('black',3)), bg='white', bty = 'n')
par(cex = 1.2)
plot(1,1, type = 'n', log = 'xy',
# xlim = range(R0.seq), ylim = range(N.seq),
xlim = c(2.94280,2.94284), ylim = c(842.160,842.164),  # use these limits to zoom into the Fisher information matrix contour
xlab = expression(R0), ylab = expression(N),
main = "-log(likelihood) contours", bty = "n")
.filled.contour(R0.seq, N.seq, mat, levels = seq(min(mat), max(mat), l=20), col = topo.colors(20))
## Add contour for 95% CI from likelihood ratio
## This comes out extremely small
## Change xlim and ylim to zoom-in further
contour(R0.seq, N.seq, mat, levels = c(conf.cutoff),
col = "black", lwd = 2, labels = "", labcex = .2, add = T)
## Add contour for 95% CI from Hessian
lines(exp(ellipse(fisherInfMatrix, centre = MLEfits, level = .95)), lty = 2)
## Add MLE to the plot
points(exp(log_R0.fit), exp(log_N.fit), pch = 16, cex = 1, col = 'black')
## Add true parameter values to the plot
legend("topleft",
c('MLE', '95% contour (profile likelihood)', '95% contour (Fisher information matrix)')
, lty = c(NA, 1, 2), pch = c(16, NA, NA),
col = c(rep('black',3)), bg='white', bty = 'n')
## Figure 1 (simulated data)
ggplot(df, aes(x = time, y = C, color = variable))+
geom_line() +
geom_point(data = myDat, mapping=aes(x = time, y=C, color = variable)) +
#  geom_ribbon(data = myDat, mapping=aes(x = time, y = samp_cinc_rate, ymin=lci, ymax=uci), color = NA, fill = "black", alpha = 0.2) +
labs(x= "Time [days]",
y= "Cumulative cases") +
scale_color_manual(labels = c("Fitted","Truth","Data"), values = c("red", "blue", "black")) +
theme(legend.title= element_blank())
## Figure 2 (actual data)
ggplot(df2, aes(x = time, y = C, color = variable))+
geom_line() +
geom_point(data = subset(df2, df2$variable == "CEN.data"), mapping=aes(x = time, y=C, color = variable)) +
labs(x= "Time [days]",
y= "Cumulative cases") +
scale_color_manual(labels = c("Model","Data"), values = c("blue", "red"))
summary(CEN.data)
## Figure 2 (actual data)
ggplot(df2, aes(x = time, y = C, color = variable))+
geom_line() +
geom_point(data = subset(df2, df2$variable == "CEN.data"), mapping=aes(x = time, y=C, color = variable)) +
labs(x= "Time [days]",
y= "Cumulative cases") +
scale_color_manual(labels = c("Model","Data"), values = c("black", "red")) +
theme(legend.title= element_blank())
## Figure 2 (actual data)
ggplot(df2, aes(x = time, y = C, color = variable))+
geom_line() +
geom_point(data = subset(df2, df2$variable == "CEN.data"), mapping=aes(x = time, y=C, color = variable)) +
labs(x= "Time [days]",
y= "Cumulative cases") +
scale_color_manual(labels = c("Data","Model"), values = c("black", "red")) +
theme(legend.title= element_blank())
## Figure 2 (actual data)
ggplot(df2, aes(x = time, y = C, color = variable))+
geom_line() +
geom_point(data = CEN.data, mapping=aes(x = time, y=C, color = variable)) +
labs(x= "Time [days]",
y= "Cumulative cases") +
scale_color_manual(labels = c("Data","Model"), values = c("black", "red")) +
theme(legend.title= element_blank())
head(myDat)
## Extract one outbreak: Centinela State Prison (CEN) Outbreak 5
CEN.data <- all.data %>%
filter(Facility_Outbreak == "Centinela State Prison (CEN) Outbreak 5") %>%
select(Date, Daily_New_Cases) %>%
slice(-1) %>%  # remove first date with 0 new cases
rename(incidence = Daily_New_Cases) %>%
mutate(C = cumsum(incidence)) %>%  # calculate cumulative incidence
mutate(time = seq(0,nrow(.)-1)) %>%
mutate(variable = "CEN.data")  # will be used for ggplot later
## Figure 2 (actual data)
ggplot(df2, aes(x = time, y = C, color = variable))+
geom_line() +
geom_point(data = CEN.data, mapping=aes(x = time, y=C, color = variable)) +
labs(x= "Time [days]",
y= "Cumulative cases") +
scale_color_manual(labels = c("Data","Model"), values = c("black", "red")) +
theme(legend.title= element_blank())
head(df)
## Figure 2 (actual data)
ggplot(prison.ts, aes(x = time, y = C, color = variable))+
geom_line() +
geom_point(data = CEN.data, mapping=aes(x = time, y=C, color = variable)) +
labs(x= "Time [days]",
y= "Cumulative cases") +
scale_color_manual(labels = c("Data","Model"), values = c("black", "red")) +
theme(legend.title= element_blank())
prison.ts <- prison.ts %>%
mutate(variable = "prison.ts")
## Figure 2 (actual data)
ggplot(prison.ts, aes(x = time, y = C, color = variable))+
geom_line() +
geom_point(data = CEN.data, mapping=aes(x = time, y=C, color = variable)) +
labs(x= "Time [days]",
y= "Cumulative cases") +
scale_color_manual(labels = c("Data","Model"), values = c("black", "red")) +
theme(legend.title= element_blank())
ggplot(prison.ts, aes(x = time, y = C, color = variable))+
geom_line() +
geom_point(data = CEN.data, mapping=aes(x = time, y=C, color = variable)) +
labs(x= "Time [days]",
y= "Cumulative cases",
title = "Comparing incidence of data and model",
subtitle = paste("CEN Outbreak 5 data
Estimates: R0 = ", round(estimParms['R0'],2), ", N = ", round(estimParms['N'],2)),
x= "Time [days]",
y= "Cases") +
scale_color_manual(labels = c("Data","Model"), values = c("black", "red")) +
theme(legend.title= element_blank())
max(CEN.data$C)   # end size of the outbreak
estimParms['N']   # the estimated N
## Extract another outbreak: San Quentin State Prison (SQ) Outbreak 1
SQ.data <- all.data %>%
filter(Facility_Outbreak == "San Quentin State Prison (SQ) Outbreak 1") %>%
select(Date, Daily_New_Cases) %>%
slice(-1) %>%                             # remove first date with 0 new cases
rename(incidence = Daily_New_Cases) %>%
mutate(C = cumsum(incidence)) %>%         # calculate cumulative incidence
mutate(time = seq(0,nrow(.)-1)) %>%
mutate(variable = "SQ.data")             # will be used for ggplot later
SQ.data
## Quick look at the daily incidence of SQ Outbreak 1
ggplot(SQ.data, aes(time, incidence)) +
geom_col() +
labs(title = "Daily Incidence of SQ Outbreak 1",
y = "Incidence (cases)")
## Quick look at the cumulative incidence of SQ Outbreak 1
ggplot(SQ.data, aes(time, C)) +
geom_col() +
labs(title = "Cumulative Incidence of SQ Outbreak 1",
y = "Cumulative incidence")
## Define time sequence and initial conditions
time.out.SQ <- seq(0, max(SQ.data$time), 1)
init.SQ <- init_cond(initI = SQ.data$C[1])
## Use optim to estimate R0
SQ.estim <- optim(par = c(log_R0 = log(1), log_N = log(1000))
, objFXN
, fixed.params = disease_params()  # defined at top of script
, obsDat = SQ.data
, init = init.SQ
, tseq = time.out.SQ
, control = list(trace = 3, maxit = 150)
, method = "SANN")
## Feed the last parameters of SANN in as the first values of Nelder-Mead
SQ.estim <- optim(par = SQ.estim$par
, objFXN
, fixed.params = disease_params()  # defined at top of script
, obsDat = SQ.data
, init = init.SQ
, tseq = time.out.SQ
, control = list(trace = 3, maxit = 800, reltol = 10^-7)
, method = "Nelder-Mead"
, hessian = T)
## Store estimates
SQfits <- SQ.estim$par
estimSQ <- exp(unname(SQfits))
names(estimSQ) <- c('R0', 'N')
## View the R0 and N estimates
estimSQ
max(SQ.data$C)
View(all.data)
ASP.data <- all.data %>%
filter(Facility_Outbreak == "Avenal State Prison (ASP) Outbreak 1") %>%
select(Date, Daily_New_Cases) %>%
slice(-1) %>%                             # remove first date with 0 new cases
rename(incidence = Daily_New_Cases) %>%
mutate(C = cumsum(incidence)) %>%         # calculate cumulative incidence
mutate(time = seq(0,nrow(.)-1)) %>%
filter(time < 60) %>%                     # restrict data to one peak of the outbreak
mutate(variable = "ASP.data")              # will be used for ggplot later
ASP.data
## Quick look at the daily incidence of SQ Outbreak 1
ggplot(ASP.data, aes(time, incidence)) +
geom_col() +
labs(title = "Daily Incidence of ASP Outbreak 1",
y = "Incidence (cases)")
## Quick look at the cumulative incidence of SQ Outbreak 1
ggplot(ASP.data, aes(time, C)) +
geom_col() +
labs(title = "Cumulative Incidence of ASP Outbreak 1",
y = "Cumulative incidence")
## Define time sequence and initial conditions
time.out.ASP <- seq(0, max(ASP.data$time), 1)
init.ASP <- init_cond(initI = ASP.data$C[1])
## Use optim to estimate R0
ASP.estim <- optim(par = c(log_R0 = log(1), log_N = log(1000))
, objFXN
, fixed.params = disease_params()  # defined at top of script
, obsDat = ASP.data
, init = init.ASP
, tseq = time.out.ASP
, control = list(trace = 3, maxit = 150)
, method = "SANN")
## Feed the last parameters of SANN in as the first values of Nelder-Mead
ASP.estim <- optim(par = ASP.estim$par
, objFXN
, fixed.params = disease_params()  # defined at top of script
, obsDat = ASP.data
, init = init.ASP
, tseq = time.out.ASP
, control = list(trace = 3, maxit = 800, reltol = 10^-7)
, method = "Nelder-Mead"
, hessian = T)
## Store estimates
ASPfits <- ASP.estim$par
estimASP <- exp(unname(ASPfits))
names(estimASP) <- c('R0', 'N')
## View the R0 and N estimates
estimASP
max(ASP.data$C)  # max cumulative incidence is greater than estimated N
estim.table <- tibble()
estim.table <- tibble(outbreak = NA, R0 = NA, N = NA)
## Initialize the table of all estimates
estim.table <- tibble(outbreak = NA, R0 = NA, N = NA, maxC = NA)
class(estimASP)
estimASP
c("hi", 5, TRUE)
c(exp(unname(ASP.estim$par),max(ASP.data$C))
)
c(exp(unname(ASP.estim$par)),max(ASP.data$C))
unique(all.data$Facility_Outbreak)
